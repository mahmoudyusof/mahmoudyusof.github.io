{"hash":"5b5f75d25e19532c39ff18cd701a577df7c533a1","data":{"article":{"content":"<h1 id=\"how-to-use-data-generators-in-tensorflow\"><a href=\"#how-to-use-data-generators-in-tensorflow\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>How to use data generators in tensorflow</h1>\n<hr>\n<h2 id=\"why-\"><a href=\"#why-\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Why ?</h2>\n<p>Believe it or not, but loading the entire dataset in memory is <strong>NOT</strong> the best idea.<br>\nIf you're dealing with a small dataset, that might work, but that is just a waste of resources, and worse if you're working on a huge dataset like the imageNet dataset, this won't work at all.</p>\n<h2 id=\"how-\"><a href=\"#how-\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>HOW ?</h2>\n<p>Python generators are lazy which means they are iterables that give you the data upon request, unlike regular lists that just store the data in memory all the time.</p>\n<p>tensorflow keras has a <code>Sequence</code> class that can be used for this purpose. <a class=\"mdlink\" href=\"https://www.tensorflow.org/api_docs/python/tf/keras/utils/Sequence\">Sequence Class API Reference</a><br>\nlet's jump into it</p>\n<h2 id=\"scenario\"><a href=\"#scenario\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Scenario</h2>\n<p>Working with images is a good example for this, so let's say that you have pictures of objects that you need to localize,<br>\nSo your features are images and labels are (x, y, h, w) for coordinate and dimensions of the containing box, and the labels and image names are stored in a csv file.</p>\n<h2 id=\"data\"><a href=\"#data\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Data</h2>\n<table>\n<thead>\n<tr>\n<th>image_file    </th>\n<th>x    </th>\n<th>y    </th>\n<th>w    </th>\n<th>h    </th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>file1.png</td>\n<td>10</td>\n<td>20</td>\n<td>50</td>\n<td>50</td>\n</tr>\n<tr>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n</tr>\n<tr>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n<td>...</td>\n</tr>\n</tbody>\n</table>\n<hr>\n<h2 id=\"code\"><a href=\"#code\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>Code</h2>\n<p>Let's define an initializer, the initializer is going to take the information needed to get the data such as:</p>\n<ul>\n<li>The csv file</li>\n<li>The directory containing all of the images</li>\n</ul>\n<p>It will also take the output shape of the batch</p>\n<ul>\n<li>The output size of each image</li>\n<li>The batch size</li>\n</ul>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">import</span> numpy <span class=\"token keyword\">as</span> np\n<span class=\"token keyword\">import</span> pandas <span class=\"token keyword\">as</span> pd\n<span class=\"token keyword\">import</span> matplotlib<span class=\"token punctuation\">.</span>image <span class=\"token keyword\">as</span> mpimg\n\n<span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>utils <span class=\"token keyword\">import</span> Sequence\n\n<span class=\"token keyword\">class</span> <span class=\"token class-name\">DataGenerator</span><span class=\"token punctuation\">(</span>Sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> csv_file<span class=\"token punctuation\">,</span> base_dir<span class=\"token punctuation\">,</span> output_size<span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token triple-quoted-string string\">\"\"\"\n  Initializes a data generator object\n    :param csv_file: file in which image names and numeric labels are stored\n    :param base_dir: the directory in which all images are stored\n    :param output_size: image output size after preprocessing\n    :param shuffle: shuffle the data after each epoch\n    :param batch_size: The size of each batch returned by __getitem__\n  \"\"\"</span>\n    self<span class=\"token punctuation\">.</span>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>csv_file<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>base_dir <span class=\"token operator\">=</span> base_dir\n    self<span class=\"token punctuation\">.</span>output_size <span class=\"token operator\">=</span> output_size\n    self<span class=\"token punctuation\">.</span>shuffle <span class=\"token operator\">=</span> shuffle\n    self<span class=\"token punctuation\">.</span>batch_size <span class=\"token operator\">=</span> batch_size\n    self<span class=\"token punctuation\">.</span>on_epoch_end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span></code></pre>\n<hr>\n<p>Now let's define some special methods starting with the one called in the initializer <code>on_epoch_end()</code> that is called after each epoch as the name may suggest, duh!</p>\n<p>We call this method in the initializer because we need the indeces attribute to be set at the begining of the first epoch, otherwise we will get an error telling us that the class has no attribute \"indecies\"</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">on_epoch_end</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  self<span class=\"token punctuation\">.</span>indices <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">:</span>\n    np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>indices<span class=\"token punctuation\">)</span></code></pre>\n<hr>\n<p>Now we need to define the length of the data, which is not the number of entries as you might think, it's actually the number of batches, this needs to be accessible by the <code>len</code> function in python so we need to define the <code>__len__</code> method.</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">__len__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token keyword\">return</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">)</span></code></pre>\n<hr>\n<p>Now let's get serious, the fun part is in the next method which is <code>__getitem__</code>.<br>\nThis function gets called on indexing or slicing like <code>data_generator[0]</code> or <code>data_generator[1:3]</code> and the index is passed as a parameter to it. Here we call it <code>idx</code></p>\n<p>In this function we shall load and preprocess the images.<br>\nThis will only be fired when keras trys to load a batch, which will save our memory.</p>\n<p>You might think splitting this into multiple functions would be a good idea ... and you'd be totally right.<br>\nThis function should return a preprocessed batch of data</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">def</span> <span class=\"token function\">__getitem__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n  <span class=\"token comment\">## Initializing Batch</span>\n  <span class=\"token comment\">#  that one in the shape is just for a one channel images</span>\n  <span class=\"token comment\"># if you want to use colored images you might want to set that to 3</span>\n  X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>output_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n  <span class=\"token comment\"># (x, y, h, w)</span>\n  y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token comment\"># get the indices of the requested batch</span>\n  indices <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>indices<span class=\"token punctuation\">[</span>idx<span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">]</span>\n\n  <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> data_index <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>indices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    img_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>base_dir<span class=\"token punctuation\">,</span>\n                self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>data_index<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n    img <span class=\"token operator\">=</span> mpimg<span class=\"token punctuation\">.</span>imread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\">## this is where you preprocess the image</span>\n    <span class=\"token comment\">## make sure to resize it to be self.output_size</span>\n\n    label <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>data_index<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\">## if you have any preprocessing for</span>\n    <span class=\"token comment\">## the labels too do it here</span>\n\n    X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> img\n    y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> label\n\n  <span class=\"token keyword\">return</span> X<span class=\"token punctuation\">,</span> y</code></pre>\n<hr>\n<p>Now you are ready to fit the model to this generator. You can also easily make a validation generator and validate your model against that, all you need to do is make a new instance of the <code>DataGenerator</code> class, and pass in the validation csv and base directory and you're good to go. That's why I love OOP.</p>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> tensorflow<span class=\"token punctuation\">.</span>keras<span class=\"token punctuation\">.</span>models <span class=\"token keyword\">import</span> Sequential\n\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n  <span class=\"token comment\">## define the model's architecture</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ntrain_gen <span class=\"token operator\">=</span> DataGenerator<span class=\"token punctuation\">(</span><span class=\"token string\">\"data.csv\"</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token string\">\"data\"</span><span class=\"token punctuation\">,</span>\n                          <span class=\"token punctuation\">(</span><span class=\"token number\">244</span><span class=\"token punctuation\">,</span> <span class=\"token number\">244</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span>\n                          batch_size<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span>\n                          shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## compile the model first of course</span>\n\n<span class=\"token comment\"># now let's train the model</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_gen<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span>\n<span class=\"token comment\">#  note you could also make a validation generator and pass it here like normal datasets</span>\n\n<span class=\"token comment\"># back in the days you had to do this</span>\n<span class=\"token comment\"># model.fit_generator(train_gen, ...)</span></code></pre>\n<hr>\n<h2 id=\"the-complete-code\"><a href=\"#the-complete-code\" aria-hidden=\"true\"><span class=\"icon icon-link\"></span></a>The complete code</h2>\n<pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">class</span> <span class=\"token class-name\">DataGenerator</span><span class=\"token punctuation\">(</span>Sequence<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__init__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> csv_file<span class=\"token punctuation\">,</span> base_dir<span class=\"token punctuation\">,</span> output_size<span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">False</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">10</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token triple-quoted-string string\">\"\"\"\n    Initializes a data generator object\n      :param csv_file: file in which image names and numeric labels are stored\n      :param base_dir: the directory in which all images are stored\n      :param output_size: image output size after preprocessing\n      :param shuffle: shuffle the data after each epoch\n      :param batch_size: The size of each batch returned by __getitem__\n    \"\"\"</span>\n    self<span class=\"token punctuation\">.</span>df <span class=\"token operator\">=</span> pd<span class=\"token punctuation\">.</span>read_csv<span class=\"token punctuation\">(</span>csv_file<span class=\"token punctuation\">)</span>\n    self<span class=\"token punctuation\">.</span>base_dir <span class=\"token operator\">=</span> base_dir\n    self<span class=\"token punctuation\">.</span>output_size <span class=\"token operator\">=</span> output_size\n    self<span class=\"token punctuation\">.</span>shuffle <span class=\"token operator\">=</span> shuffle\n    self<span class=\"token punctuation\">.</span>batch_size <span class=\"token operator\">=</span> batch_size\n    self<span class=\"token punctuation\">.</span>on_epoch_end<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">on_epoch_end</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    self<span class=\"token punctuation\">.</span>indices <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>arange<span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token keyword\">if</span> self<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">:</span>\n      np<span class=\"token punctuation\">.</span>random<span class=\"token punctuation\">.</span>shuffle<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>indices<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__len__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token keyword\">return</span> <span class=\"token builtin\">int</span><span class=\"token punctuation\">(</span><span class=\"token builtin\">len</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">)</span> <span class=\"token operator\">/</span> self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">)</span>\n\n  <span class=\"token keyword\">def</span> <span class=\"token function\">__getitem__</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">,</span> idx<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n    <span class=\"token comment\">## Initializing Batch</span>\n    <span class=\"token comment\">#  that one in the shape is just for a one channel images</span>\n    <span class=\"token comment\"># if you want to use colored images you might want to set that to 3</span>\n    X <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>output_size<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n    <span class=\"token comment\"># (x, y, h, w)</span>\n    y <span class=\"token operator\">=</span> np<span class=\"token punctuation\">.</span>empty<span class=\"token punctuation\">(</span><span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">,</span> <span class=\"token number\">4</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\n\n    <span class=\"token comment\"># get the indices of the requested batch</span>\n    indices <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>indices<span class=\"token punctuation\">[</span>idx<span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">:</span><span class=\"token punctuation\">(</span>idx<span class=\"token operator\">+</span><span class=\"token number\">1</span><span class=\"token punctuation\">)</span><span class=\"token operator\">*</span>self<span class=\"token punctuation\">.</span>batch_size<span class=\"token punctuation\">]</span>\n\n    <span class=\"token keyword\">for</span> i<span class=\"token punctuation\">,</span> data_index <span class=\"token keyword\">in</span> <span class=\"token builtin\">enumerate</span><span class=\"token punctuation\">(</span>indices<span class=\"token punctuation\">)</span><span class=\"token punctuation\">:</span>\n      img_path <span class=\"token operator\">=</span> os<span class=\"token punctuation\">.</span>path<span class=\"token punctuation\">.</span>join<span class=\"token punctuation\">(</span>self<span class=\"token punctuation\">.</span>base_dir<span class=\"token punctuation\">,</span>\n                  self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>data_index<span class=\"token punctuation\">,</span> <span class=\"token number\">0</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\n      img <span class=\"token operator\">=</span> mpimg<span class=\"token punctuation\">.</span>imread<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n      img <span class=\"token operator\">=</span> cv2<span class=\"token punctuation\">.</span>cvtColor<span class=\"token punctuation\">(</span>img<span class=\"token punctuation\">,</span> cv2<span class=\"token punctuation\">.</span>COLOR_RGB2GRAY<span class=\"token punctuation\">)</span> <span class=\"token comment\"># to reduce it to one channel to match the shape</span>\n      <span class=\"token comment\">## this is where you preprocess the image</span>\n      <span class=\"token comment\">## make sure to resize it to be self.output_size</span>\n\n      label <span class=\"token operator\">=</span> self<span class=\"token punctuation\">.</span>df<span class=\"token punctuation\">.</span>iloc<span class=\"token punctuation\">[</span>data_index<span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">.</span>to_numpy<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n      <span class=\"token comment\">## if you have any preprocessing for</span>\n      <span class=\"token comment\">## the labels too do it here</span>\n\n      X<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">,</span><span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> img\n      y<span class=\"token punctuation\">[</span>i<span class=\"token punctuation\">]</span> <span class=\"token operator\">=</span> label\n\n    <span class=\"token keyword\">return</span> X<span class=\"token punctuation\">,</span> y\n\n\n<span class=\"token comment\">## Defining and training the model</span>\n\nmodel <span class=\"token operator\">=</span> Sequential<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span>\n  <span class=\"token comment\">## define the model's architecture</span>\n<span class=\"token punctuation\">]</span><span class=\"token punctuation\">)</span>\n\ntrain_gen <span class=\"token operator\">=</span> DataGenerator<span class=\"token punctuation\">(</span><span class=\"token string\">\"data.csv\"</span><span class=\"token punctuation\">,</span> <span class=\"token string\">\"data\"</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">(</span><span class=\"token number\">244</span><span class=\"token punctuation\">,</span> <span class=\"token number\">244</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">,</span> batch_size<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> shuffle<span class=\"token operator\">=</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\">## compile the model first of course</span>\n\n<span class=\"token comment\"># now let's train the model</span>\nmodel<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>train_gen<span class=\"token punctuation\">,</span> epochs<span class=\"token operator\">=</span><span class=\"token number\">5</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">.</span><span class=\"token punctuation\">)</span></code></pre>\n<hr>\n<p>And that's it.. you've just created your dataset generator that loads the data into memory batch by batch instead of the whole thing at once.<br>\nI hope this was useful.</p>\n<hr>\n<p><a class=\"mdlink\" href=\"https://stanford.edu/~shervine/blog/keras-how-to-generate-data-on-the-fly\">Reference Article</a></p>\n<p><a class=\"mdlink\" href=\"https://github.com/mahmoudyusof/facial_keypoint_detection\">My Notebooks</a></p>\n","id":"b5c959723ac871fa3ac46812de39f83b","title":"Data Generators In Tensorflow","type":"article","description":"explaining how to load batches of data into memory instead of the entire dataset for more effeciency","image":"https://mahmoudyusof.github.io/seo_images/data-generator.jpg","url":"https://mahmoudyusof.github.io/facial-keypoint-detection/data-generator/"}},"context":{}}